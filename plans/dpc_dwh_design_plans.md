# DPC DWH 設計書作成計画

本ドキュメントは、DPCデータ仕様に基づくAWS Redshift DWH基盤の設計書（1)〜13)）を作成するための準備計画をまとめたものです。各計画では目的に沿った構成案、必要な情報ソース、作業ステップ、成果物テンプレートの骨子を定義します。

## 共通前提
- 参照情報
  - 厚生労働省 DPC実施説明資料（2025年度版）および補完資料
  - 既存分析メモ（提供済み説明文）
  - AWS公式ドキュメント（Redshift, Step Functions, Lambda, Glue, S3, IAM 等）
- 設計書の表記ルール
  - すべて Markdown 形式で作成
  - Mermaid 図の利用（指示がある場合）
  - 用語統一（DPCコード、施設コードなど）
- 作成プロセス
  1. 情報整理（仕様抽出、関係者ヒアリング想定）
  2. たたき台作成（目次→詳細記述）
  3. レビュー & フィードバック反映
  4. 最終版確定

以下、各設計書の個別計画です。

---

## 1. 全体アーキテクチャ設計（AWS）
- **目的再確認**: DPC基盤全体像（コンポーネント、データフロー、セキュリティ境界）を読者に提示する。
- **必要情報**
  - データフロー要件（Ingest→COPY→dbt→DQ→Export）
  - 使用サービスの構成要素（S3, Redshift, Glue Catalog, Step Functions, EventBridge, Lambda, dbt, QuickSight）
  - ネットワーク要件（Public不要、VPC境界）
- **作業ステップ**
  1. 想定ユーザー/ワークロードの洗い出し
  2. コンポーネント一覧と役割整理
  3. Mermaid コンポーネント図とデータフロー図のドラフト作成
  4. VPC/サブネット/IAM/KMS/セキュリティ記述案の作成
  5. 決定事項・未決事項を整理
- **成果物構成案**
  - 概要と目的
  - システム構成図（Mermaid）
  - データフロー図（Mermaid）
  - コンポーネント詳細
  - VPC・サブネット配置
  - IAMロール/KMS鍵/Security Boundary
  - 運用ポイント
  - 決定事項/未決事項

## 2. ネットワーク & セキュリティ設計
- **目的再確認**: VPC内配置と暗号化・権限制御の設計を明文化。
- **必要情報**
  - VPC CIDR、サブネット分割方針
  - NAT Gateway要否、エンドポイント（S3, Redshift Data API）要件
  - IAMロール/ポリシー要件
  - 暗号化要件（S3, Redshift, TLS）
  - 監査ログ要件（CloudTrail, CloudWatch Logs）
- **作業ステップ**
  1. VPCトポロジ設計（AZ、サブネット、ルートテーブル）
  2. セキュリティグループ/NACL要件整理
  3. 暗号化/KMS鍵管理方針の定義
  4. IAMロールとポリシーのJSONスケルトン作成
  5. 監査ログ出力設計
- **成果物構成案**
  - ネットワーク概要図（文章＋表）
  - VPC/サブネット/NAT/エンドポイント詳細
  - セキュリティ設定（SG, NACL, TLS）
  - IAMロール/ポリシー（JSONスケルトン付）
  - 暗号化設定
  - ログ・監査設計

## 3. S3 データ配置・命名規約
- **目的再確認**: Rawデータ格納ルールと命名規約を統一。
- **必要情報**
  - 対象ファイルタイプと属性（様式1〜K）
  - 学習用バケット命名方針
  - 監査用マニフェスト要件（件数、ハッシュ、施設コード、作成時刻）
  - ライフサイクルポリシー期間
- **作業ステップ**
  1. S3バケット階層案の作成
  2. 命名規約表（パス、ファイル名、サフィックス）作成
  3. _manifest.json スキーマ定義
  4. ライフサイクルルール（archive/へ移行期間）決定
- **成果物構成案**
  - 概要
  - ディレクトリ構造図
  - 命名規約表（例付き）
  - マニフェストJSONスキーマ（例）
  - ライフサイクル設定

## 4. 論理データモデル（ERD）
- **目的再確認**: DPC 7ファイルの論理リレーション確立。
- **必要情報**
  - 各ファイルの主キー/外部キー
  - 多重度（1:多 等）
  - 結合キー（facility_cd + data_id 等）
- **作業ステップ**
  1. 各ファイルのキー定義整理
  2. Mermaid ERDのドラフト
  3. キー定義表（主キー/外部キー/備考）作成
- **成果物構成案**
  - モデル概要
  - Mermaid ERDコード
  - キー定義表（Markdown）
  - 補足説明

## 5. 物理データモデル（Redshift DDL）
- **目的再確認**: raw/stage/mart/ref のテーブルDDLを定義。
- **必要情報**
  - 各層のカラム仕様
  - 分散スタイル・ソートキー方針
  - 主キー/外部キー（NOT ENFORCED）
  - コメント方針
- **作業ステップ**
  1. Raw層: 仕様項目列挙と型定義
  2. Stage層: EF統合ロジックと派生列（total_qty等）
  3. Mart層: fact_case_summary / fact_cost_monthly / fact_dx_outcome の列設計
  4. Ref層: dimテーブル構造（facility, dpc_code, icd10, date）
  5. DDL化（CREATE TABLE ...）とコメント
- **成果物構成案**
  - 層別概要
  - テーブルごとのDDL（SQLブロック）
  - 設計上の注記（DISTKEY, SORTKEY理由）

## 6. dbt プロジェクト設計
- **目的再確認**: dbt構成と規約を定義。
- **必要情報**
  - ディレクトリ構造（models, seeds, tests, macros, snapshots）
  - 命名規則とタグ/メタデータ
  - テストの適用例
  - ドキュメント生成運用
- **作業ステップ**
  1. プロジェクト構造図の作成
  2. 命名規約と所有者メタの定義
  3. テスト適用例（not_null, unique, relationships, accepted_values）記述
  4. dbt_project.yml, models.yml サンプル作成
  5. 運用フロー（docs generate 等）整理
- **成果物構成案**
  - 概要
  - ディレクトリ/命名規則
  - テストポリシー
  - dbt_project.yml サンプル
  - models.yml サンプル
  - ドキュメント運用

## 7. ELT パイプライン設計（Step Functions + dbt + Python）
- **目的再確認**: バッチDAGの実行設計と再実行戦略策定。
- **必要情報**
  - ワークフロー（EventBridge→Step Functions→Lambda→Redshift Data API→dbt）
  - フェーズ詳細（validate_manifest など）
  - エラー処理/リトライ要件
  - ASL定義要素、Lambda入出力形式
- **作業ステップ**
  1. フェーズごとの入出力と処理内容を分解
  2. Step Functions 状態遷移図草案（Mermaidアクティビティ図含む）
  3. ASL（JSON）雛形の作成
  4. Lambda引数仕様、dbtコマンド列挙
  5. エラーハンドリングと再実行ポリシー記述
- **成果物構成案**
  - 概要
  - DAG説明
  - ASL雛形
  - Lambdaインターフェース仕様
  - dbtコマンド一覧
  - エラーハンドリング
  - Mermaidアクティビティ図

## 8. データ品質（DQ）ルール設計とSQL
- **目的再確認**: 重大/警告レベルのDQチェックと結果格納方法。
- **必要情報**
  - チェック対象ルール（主キー重複、退院<入院 等）
  - dq.results_yyyymm テーブル仕様
  - 通知フロー（Slack擬似コード）
- **作業ステップ**
  1. ルール一覧と分類（重大/警告）
  2. 各ルールのSQLサンプル作成
  3. dq.results_yyyymm テーブル定義とINSERT例
  4. しきい値設定理由記述
  5. 通知ロジック（疑似コード）作成
- **成果物構成案**
  - 概要
  - 重大ルール詳細（SQL付）
  - 警告ルール詳細（SQL付）
  - 結果テーブル定義と運用
  - 通知フロー

## 9. 観測・運用（WLM/メトリクス/アラート/メンテ）
- **目的再確認**: Redshift運用監視とメンテ計画策定。
- **必要情報**
  - WLM設定方針（バッチ/アドホック）
  - 監視メトリクス一覧と閾値
  - CloudWatchダッシュボード構成案
  - Runbook手順
- **作業ステップ**
  1. ワークロード分類とWLMキュー設計
  2. 監視指標と閾値の決定
  3. CloudWatchダッシュボードWidget定義
  4. Runbook（一次切り分け→復旧）作成
- **成果物構成案**
  - WLM設計
  - 監視メトリクス表
  - CloudWatchダッシュボード定義
  - アラート設定
  - Runbook

## 10. パフォーマンス設計（物理最適化）
- **目的再確認**: DIST/SORT根拠と代表クエリ最適化策をまとめる。
- **必要情報**
  - 代表クエリ（LOS、30日再入院率、費用分解）のSQL草案
  - DIST/SORT設定理由
  - MV候補とリフレッシュ方式
  - EXPLAIN計画の読み方と改善例
- **作業ステップ**
  1. 代表クエリの要件整理とSQLドラフト
  2. テーブル別 DIST/SORT 根拠表作成
  3. MV/CTAS候補の洗い出し
  4. Before/After 指標想定（スキャン量、実行時間）
  5. EXPLAIN サンプルと改善ステップ記述
- **成果物構成案**
  - 概要
  - DIST/SORT根拠表
  - 代表クエリと最適化施策（Before/After）
  - MV候補と更新方式
  - EXPLAIN読解と改善手順

## 11. CI/CD & 環境昇格
- **目的再確認**: Git運用とデプロイフロー定義。
- **必要情報**
  - 環境構成（dev→stg→prod）
  - GitHub Actionsによる dbt build / DDL 適用手順
  - Secrets管理（Redshift接続、AWS資格情報等）
  - ロールバック戦略
- **作業ステップ**
  1. ブランチ戦略とレビュー手順整理
  2. GitHub Actions ワークフロー雛形作成
  3. 環境変数・Secrets一覧作成
  4. 破壊的変更ガード（検出ロジック等）定義
  5. ロールバック手順記述
- **成果物構成案**
  - 運用方針
  - 環境構成図
  - Actions YAMLサンプル
  - Secrets一覧表
  - ロールバック手順

## 12. テスト計画（E2E/回帰）
- **目的再確認**: サンプルデータでの自動検証設計。
- **必要情報**
  - テスト観点（件数、合計点数、KPIなど）
  - E2Eフロー（S3→COPY→dbt→DQ→QuickSight）
  - 回帰テスト手段（dbt tests + pytest）
- **作業ステップ**
  1. テスト観点表作成（E2E, 回帰）
  2. E2Eシナリオ手順書作成
  3. pytest 雛形とdbt tests コマンド列挙
  4. ゴールデンデータ比較方法定義
- **成果物構成案**
  - テスト方針
  - 観点表
  - E2E手順
  - 回帰テスト構成（pytest, dbt tests）
  - 判定基準

## 13. データ提供（学習用エクスポート）
- **目的再確認**: mart層からの匿名集計出力とドキュメント整備。
- **必要情報**
  - 出力対象マート（fact_case_summary等）
  - 出力形式（CSV/Parquet）、S3パス
  - データ辞書項目
  - バージョン管理方針（タグ付け）
- **作業ステップ**
  1. エクスポート対象と粒度を定義
  2. Exportクエリ草案作成
  3. LambdaによるS3出力フロー設計（サンプルコード）
  4. データ辞書テンプレート作成
  5. バージョニングと公開プロセス整理
- **成果物構成案**
  - 概要
  - Exportクエリ例
  - Lambdaサンプルコード
  - データ辞書テンプレート
  - バージョン管理ポリシー

---

## 決定事項 / 未決事項 収集方針
- 各設計書の末尾に「決定事項/未決事項」節を設け、以下を記録する。
  - **決定事項**: 前提として確定した設定・ポリシー。
  - **未決事項**: 利用部門との合意が必要な項目、追加調査が必要な項目。
- 設計書作成時には、本計画で明記した調査ポイントを基に情報を埋めていく。

